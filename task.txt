Please read the instructions/rule carefully (if something is unclear, please ask).

Rules / General comments:
  * Avoid using external libraries (or add a note saying why you need them).
  * The code should run on a laptop without specialized hardware and finish in a reasonable amount of time (<10min).
  * Please provide a short documentation of your code and how to run it.
  * The main criterion is not performance, but the quality of the code wrt. readability and best practices in ML and Python.
  * The task is intended to be very simple and should be solvable in 1-3 hours.

Goal:

Please send me your code (or a link where you uploaded it) and the produced output from running it (log files,
plots, etc.) along with some description on how to run it. There is no single correct solution. We will use your
solution as the starting point for a discussion in the meeting. So, also be prepared to run and present the code when we
meet next.

Good luck and have fun!

## Task

You are an AutoML enthusiast and DL expert. Your colleague asks you to design a neural network for tabular data for a
binary classification task. To start simple, you plan to first focus on a small and simple feed forward network. Of
course, you want to optimize its most important hyperparameters automatically and compare the found configuration to
the commonly used baseline, [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html). Furthermore, to better
understand how well random search performs, you also want to plot the validation accuracy of the best found solution over time.


### Steps

  * Load data (see below). Split and preprocess it as necessary, e.g. using scikit-learn
  * Pick a evaluation metric (e.g., accuracy, F1, AUC, ...)
  * Evaluate XGBoost as a baseline
  * Implement a simple feed forward network with a few layers using PyTorch
  * Pick at least three hyperparameters to optimize and implement a random search
  * Evaluate 20 iterations of random search, for each iteration print the configuration and its performance
  * Create a plot to show the performance of the current best configuration per random search iteration
  * Compare the best found configuration to the results obtained with XGBoost


### Code to load dataset

Use this template to load the data from OpenML. You can also use a different dataset if you prefer. For this you need to have
openml, sklearn and numpy installed (`pip install openml sklearn numpy`). Running it for the first time will download the data.

```python
import openml
import sklearn
import numpy as np

def get_dataset(did: int = 31) -> tuple[np.ndarray, ...]:
    """Download dataset from OpenML. Dataset id 31 is credit-g and 43898 is adult
    (for more details see openml.org/d/<did>). Both are fine for this task."""
    dataset = openml.datasets.get_dataset(did)
    X, y, cats, _ = dataset.get_data(
        dataset_format="dataframe",
        target=dataset.default_target_attribute,
    )
    _y = sklearn.preprocessing.LabelEncoder().fit_transform(y).reshape([-1, 1])
    return X, _y, cats
``

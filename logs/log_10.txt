/home/jonas/.local/lib/python3.10/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.
  warnings.warn(
##################################################################################################
Start preprocessing
Data loaded
Preprocessing done
Train and test data saved
##################################################################################################
Start Training XGBoost classifier
Model saved
##################################################################################################
Start Random Search Optimization for Neural Network
start searching!
Iteration 1 done
Current best parameter-set: lr = 0.00033254174656482493,               weight-decay = 0.00760644772955737,               batch_size = 29.0,               layer-size = 26.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 2 done
Current best parameter-set: lr = 0.00033254174656482493,               weight-decay = 0.00760644772955737,               batch_size = 29.0,               layer-size = 26.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 3 done
Current best parameter-set: lr = 0.00033254174656482493,               weight-decay = 0.00760644772955737,               batch_size = 29.0,               layer-size = 26.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 4 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 5 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 6 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 7 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 8 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 9 done
Current best parameter-set: lr = 0.0009386203914581323,               weight-decay = 0.0023380321896499536,               batch_size = 40.0,               layer-size = 8.0,               layers = 3.0,               F1-validation-score = 0.8292682926829269
Iteration 10 done
Current best parameter-set: lr = 0.0008054469369318791,               weight-decay = 0.005350672947051456,               batch_size = 38.0,               layer-size = 14.0,               layers = 7.0,               F1-validation-score = 0.8333333333333333
Iteration 11 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 12 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 13 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 14 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 15 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 16 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 17 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 18 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 19 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Iteration 20 done
Current best parameter-set: lr = 0.000994772433208648,               weight-decay = 0.005060687906383712,               batch_size = 15.0,               layer-size = 6.0,               layers = 2.0,               F1-validation-score = 0.8598130841121494
Data saved!
Model saved!
Elapsed time:
4.055701140562693 minutes
##################################################################################################
Start testing
Models loaded
Data loaded
F1 score MLP: 0.835820895522388, F1 score XGBoost: 0.8873720136518771

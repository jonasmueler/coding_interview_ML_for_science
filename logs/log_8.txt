/home/jonas/.local/lib/python3.10/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.
  warnings.warn(
##################################################################################################
Start preprocessing
Data loaded
Preprocessing done
Train and test data saved
##################################################################################################
Start Training XGBoost classifier
Model saved
##################################################################################################
Start Random Search Optimization for Neural Network
start searching!
Iteration 1 done
Current best parameter-set: lr = 0.00021653330589957987,               weight-decay = 0.003647157632904522,               batch_size = 14.0,               layer-size = 23.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 2 done
Current best parameter-set: lr = 0.00021653330589957987,               weight-decay = 0.003647157632904522,               batch_size = 14.0,               layer-size = 23.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 3 done
Current best parameter-set: lr = 0.00021653330589957987,               weight-decay = 0.003647157632904522,               batch_size = 14.0,               layer-size = 23.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 4 done
Current best parameter-set: lr = 0.00021653330589957987,               weight-decay = 0.003647157632904522,               batch_size = 14.0,               layer-size = 23.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 5 done
Current best parameter-set: lr = 0.00021653330589957987,               weight-decay = 0.003647157632904522,               batch_size = 14.0,               layer-size = 23.0,               layers = 5.0,               F1-validation-score = 0.8253968253968255
Iteration 6 done
Current best parameter-set: lr = 0.0008864227571885847,               weight-decay = 0.002131952070163066,               batch_size = 24.0,               layer-size = 29.0,               layers = 3.0,               F1-validation-score = 0.832
Iteration 7 done
Current best parameter-set: lr = 0.0008864227571885847,               weight-decay = 0.002131952070163066,               batch_size = 24.0,               layer-size = 29.0,               layers = 3.0,               F1-validation-score = 0.832
Iteration 8 done
Current best parameter-set: lr = 0.0008864227571885847,               weight-decay = 0.002131952070163066,               batch_size = 24.0,               layer-size = 29.0,               layers = 3.0,               F1-validation-score = 0.832
Iteration 9 done
Current best parameter-set: lr = 0.0008864227571885847,               weight-decay = 0.002131952070163066,               batch_size = 24.0,               layer-size = 29.0,               layers = 3.0,               F1-validation-score = 0.832
Iteration 10 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 11 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 12 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 13 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 14 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 15 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 16 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 17 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 18 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 19 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Iteration 20 done
Current best parameter-set: lr = 0.0009740700686152653,               weight-decay = 0.007267363785033602,               batch_size = 34.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8333333333333333
Data saved!
Model saved!
Elapsed time:
5.4770834366480505 minutes
##################################################################################################
Start testing
Models loaded
Data loaded
F1 score MLP: 0.8338368580060423, F1 score XGBoost: 0.8873720136518771

/home/jonas/.local/lib/python3.10/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.
  warnings.warn(
##################################################################################################
Start preprocessing
Data loaded
Preprocessing done
Train and test data saved
##################################################################################################
Start Training XGBoost classifier
Model saved
##################################################################################################
Start Random Search Optimization for Neural Network
start searching!
Iteration 1 done
Current best parameter-set: lr = 0.00024090959829819008,               weight-decay = 0.0031162432465103823,               batch_size = 44.0,               layer-size = 9.0,               layers = 6.0,               F1-validation-score = 0.787878787878788
Iteration 2 done
Current best parameter-set: lr = 0.00024090959829819008,               weight-decay = 0.0031162432465103823,               batch_size = 44.0,               layer-size = 9.0,               layers = 6.0,               F1-validation-score = 0.787878787878788
Iteration 3 done
Current best parameter-set: lr = 0.00042821363033968354,               weight-decay = 0.0030001088646056115,               batch_size = 14.0,               layer-size = 5.0,               layers = 2.0,               F1-validation-score = 0.8188976377952756
Iteration 4 done
Current best parameter-set: lr = 0.00042821363033968354,               weight-decay = 0.0030001088646056115,               batch_size = 14.0,               layer-size = 5.0,               layers = 2.0,               F1-validation-score = 0.8188976377952756
Iteration 5 done
Current best parameter-set: lr = 0.00042821363033968354,               weight-decay = 0.0030001088646056115,               batch_size = 14.0,               layer-size = 5.0,               layers = 2.0,               F1-validation-score = 0.8188976377952756
Iteration 6 done
Current best parameter-set: lr = 0.00042821363033968354,               weight-decay = 0.0030001088646056115,               batch_size = 14.0,               layer-size = 5.0,               layers = 2.0,               F1-validation-score = 0.8188976377952756
Iteration 7 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 8 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 9 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 10 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 11 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 12 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 13 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 14 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 15 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 16 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 17 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 18 done
Current best parameter-set: lr = 0.0006684403911391131,               weight-decay = 0.0095653448970095,               batch_size = 18.0,               layer-size = 23.0,               layers = 6.0,               F1-validation-score = 0.8387096774193548
Iteration 19 done
Current best parameter-set: lr = 0.000917694017609008,               weight-decay = 0.009112803338667428,               batch_size = 29.0,               layer-size = 26.0,               layers = 2.0,               F1-validation-score = 0.8455284552845529
Iteration 20 done
Current best parameter-set: lr = 0.000917694017609008,               weight-decay = 0.009112803338667428,               batch_size = 29.0,               layer-size = 26.0,               layers = 2.0,               F1-validation-score = 0.8455284552845529
Data saved!
Model saved!
Elapsed time:
6.399611763159434 minutes
##################################################################################################
Start testing
Models loaded
Data loaded
F1 score MLP: 0.8383233532934132, F1 score XGBoost: 0.8873720136518771

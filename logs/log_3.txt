/home/jonas/.local/lib/python3.10/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.
  warnings.warn(
##################################################################################################
Start preprocessing
Data loaded
Preprocessing done
Train and test data saved
##################################################################################################
Start Training XGBoost classifier
Model saved
##################################################################################################
Start Random Search Optimization for Neural Network
start searching!
Iteration 1 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 2 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 3 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 4 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 5 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 6 done
Current best parameter-set: lr = 0.0009441528234413188,               weight-decay = 0.0032762365446685595,               batch_size = 16.0,               layer-size = 24.0,               layers = 4.0,               F1-validation-score = 0.8253968253968255
Iteration 7 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 8 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 9 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 10 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 11 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 12 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 13 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 14 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 15 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 16 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 17 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 18 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 19 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Iteration 20 done
Current best parameter-set: lr = 0.0009951667841659806,               weight-decay = 0.0032887074489367277,               batch_size = 33.0,               layer-size = 10.0,               layers = 6.0,               F1-validation-score = 0.8292682926829269
Data saved!
Model saved!
Elapsed time:
8.737854115168254 minutes
##################################################################################################
Start testing
Models loaded
Data loaded
F1 score MLP: 0.8501529051987767, F1 score XGBoost: 0.8873720136518771

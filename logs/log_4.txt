/home/jonas/.local/lib/python3.10/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.
  warnings.warn(
##################################################################################################
Start preprocessing
Data loaded
Preprocessing done
Train and test data saved
##################################################################################################
Start Training XGBoost classifier
Model saved
##################################################################################################
Start Random Search Optimization for Neural Network
start searching!
Iteration 1 done
Current best parameter-set: lr = 0.0006786971054896212,               weight-decay = 0.0061302234092949544,               batch_size = 28.0,               layer-size = 10.0,               layers = 2.0,               F1-validation-score = 0.8125000000000001
Iteration 2 done
Current best parameter-set: lr = 0.0006786971054896212,               weight-decay = 0.0061302234092949544,               batch_size = 28.0,               layer-size = 10.0,               layers = 2.0,               F1-validation-score = 0.8125000000000001
Iteration 3 done
Current best parameter-set: lr = 0.0006786971054896212,               weight-decay = 0.0061302234092949544,               batch_size = 28.0,               layer-size = 10.0,               layers = 2.0,               F1-validation-score = 0.8125000000000001
Iteration 4 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 5 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 6 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 7 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 8 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 9 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 10 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 11 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 12 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 13 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 14 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 15 done
Current best parameter-set: lr = 0.00040700397937841687,               weight-decay = 0.006065310146405839,               batch_size = 13.0,               layer-size = 7.0,               layers = 7.0,               F1-validation-score = 0.832
Iteration 16 done
Current best parameter-set: lr = 0.000973463690452663,               weight-decay = 0.001579367306166782,               batch_size = 29.0,               layer-size = 21.0,               layers = 7.0,               F1-validation-score = 0.8455284552845529
Iteration 17 done
Current best parameter-set: lr = 0.000973463690452663,               weight-decay = 0.001579367306166782,               batch_size = 29.0,               layer-size = 21.0,               layers = 7.0,               F1-validation-score = 0.8455284552845529
Iteration 18 done
Current best parameter-set: lr = 0.000973463690452663,               weight-decay = 0.001579367306166782,               batch_size = 29.0,               layer-size = 21.0,               layers = 7.0,               F1-validation-score = 0.8455284552845529
Iteration 19 done
Current best parameter-set: lr = 0.000973463690452663,               weight-decay = 0.001579367306166782,               batch_size = 29.0,               layer-size = 21.0,               layers = 7.0,               F1-validation-score = 0.8455284552845529
Iteration 20 done
Current best parameter-set: lr = 0.000973463690452663,               weight-decay = 0.001579367306166782,               batch_size = 29.0,               layer-size = 21.0,               layers = 7.0,               F1-validation-score = 0.8455284552845529
Data saved!
Model saved!
Elapsed time:
8.752561418215434 minutes
##################################################################################################
Start testing
Models loaded
Data loaded
F1 score MLP: 0.8259587020648967, F1 score XGBoost: 0.8873720136518771
